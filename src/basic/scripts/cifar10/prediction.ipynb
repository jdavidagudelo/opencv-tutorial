{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py\n",
    "from basic.scripts.cifar10.model_function import get_estimator\n",
    "from basic.scripts.cifar10.utils import bytes_feature, int64_feature\n",
    "from basic.scripts.cifar10.config import RunConfig\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2884417940>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': gpu_options {\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/home/jdavidagudelo/Documents/data_sets/minist/model/'}\n"
     ]
    }
   ],
   "source": [
    "# The directory where the input data is stored\n",
    "data_dir = '/home/jdavidagudelo/Documents/data_sets/minist/'\n",
    "# The directory where the model will be stored\n",
    "job_dir = '/home/jdavidagudelo/Documents/data_sets/minist/model/'\n",
    "# Where to locate variable operations\n",
    "variable_strategy = 'CPU'\n",
    "# For usage with GPUs\n",
    "num_gpus = 0\n",
    "# Number of layers of the model\n",
    "num_layers = 44\n",
    "train_steps = 10000\n",
    "train_batch_size = 128\n",
    "eval_batch_size = 100\n",
    "# Momentum for momentum optimizer\n",
    "momentum = 0.9\n",
    "# weight decay for convolution\n",
    "weight_decay = 2e-4\n",
    "\n",
    "learning_rate = 0.1\n",
    "use_distortion_for_training = False\n",
    "sync = False\n",
    "num_intra_threads = 0\n",
    "num_inter_threads = 0\n",
    "data_format = None\n",
    "log_device_placement = False\n",
    "batch_norm_decay = 0.997\n",
    "batch_norm_epsilon = 1e-5\n",
    "kwargs = {\n",
    "    'data_dir': data_dir,\n",
    "    'job_dir': job_dir, 'variable_strategy': variable_strategy, 'num_gpus': num_gpus,\n",
    "    'num_layers': num_layers, 'train_steps': train_steps, 'train_batch_size': train_batch_size,\n",
    "    'eval_batch_size': eval_batch_size, 'momentum': momentum, 'weight_decay': weight_decay,\n",
    "    'learning_rate': learning_rate, 'use_distortion_for_training': use_distortion_for_training,\n",
    "    'sync': sync, 'num_intra_threads': num_intra_threads, 'num_inter_threads': num_inter_threads,\n",
    "    'data_format': data_format, 'log_device_placement': log_device_placement, \n",
    "    'batch_norm_decay': batch_norm_decay, 'batch_norm_epsilon': batch_norm_epsilon\n",
    "}\n",
    "sess_config = tf.ConfigProto(\n",
    "        allow_soft_placement=True,\n",
    "        log_device_placement=log_device_placement,\n",
    "        intra_op_parallelism_threads=num_intra_threads,\n",
    "        gpu_options=tf.GPUOptions(force_gpu_compatible=True))\n",
    "\n",
    "config = RunConfig(\n",
    "        session_config=sess_config, model_dir=job_dir)\n",
    "estimator, _, _ = get_estimator(data_dir=data_dir, num_gpus=num_gpus, variable_strategy=variable_strategy, \n",
    "              run_config=config, hparams=tf.contrib.training.HParams(is_chief=config.is_chief, **kwargs),\n",
    "             use_distortion_for_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAMN\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('/home/jdavidagudelo/Documents/data_sets/minist/Images/train/15.png', flags=cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img)\n",
    "print('DAMN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'input_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-59f96d59d6d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'input_fn'"
     ]
    }
   ],
   "source": [
    "result = estimator.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Estimator.predict of <tensorflow.python.estimator.estimator.Estimator object at 0x7f28a47212b0>>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = tf.train.Example(features=tf.train.Features(\n",
    "    feature={\n",
    "        'image': bytes_feature(img.tobytes()),\n",
    "        'label': int64_feature(4)\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    return [example], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = estimator.predict(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-3b55e331d156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-3b55e331d156>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/src-dbrcwOEG/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    541\u001b[0m             input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[1;32m    542\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 543\u001b[0;31m             features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# Call to warm_start has to be after model_fn is called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/src-dbrcwOEG/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/opencv-tutorial/src/basic/scripts/cifar10/model_function.py\u001b[0m in \u001b[0;36m_resnet_model_fn\u001b[0;34m(features, labels, mode, params)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_setter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                         loss, gradvars, preds = _tower_fn(\n\u001b[0;32m---> 78\u001b[0;31m                             \u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtower_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtower_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                             \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                             params.batch_norm_epsilon)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(p for p in p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
